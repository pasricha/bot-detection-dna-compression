{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bot Detection using Digital DNA Compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import sys\n",
    "import time\n",
    "import zlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import utils\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Digital DNA\n",
    "\n",
    "Model account behaviour by defining the following alphabet, of cardinality N = 3,\n",
    "\n",
    "$B^3_{type} = {\\{A, C, T\\}}$\n",
    "\n",
    "A $\\leftarrow$ tweet,\n",
    "\n",
    "C $\\leftarrow$ reply,\n",
    "\n",
    "T $\\leftarrow$ retweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User profile data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Users\n",
    "\n",
    "# Genuine accounts.\n",
    "gen = pd.read_csv('./datasets_full/datasets_full.csv/genuine_accounts.csv/users.csv')\n",
    "\n",
    "# Social spambots.\n",
    "ss1 = pd.read_csv('./datasets_full/datasets_full.csv/social_spambots_1.csv/users.csv')\n",
    "ss2 = pd.read_csv('./datasets_full/datasets_full.csv/social_spambots_2.csv/users.csv')\n",
    "ss3 = pd.read_csv('./datasets_full/datasets_full.csv/social_spambots_3.csv/users.csv')\n",
    "\n",
    "# Traditional spambots.\n",
    "# ts1 = pd.read_csv('./datasets_full/datasets_full.csv/traditional_spambots_1.csv/users.csv')\n",
    "# ts2 = pd.read_csv('./datasets_full/datasets_full.csv/traditional_spambots_2.csv/users.csv')\n",
    "# ts3 = pd.read_csv('./datasets_full/datasets_full.csv/traditional_spambots_3.csv/users.csv')\n",
    "# ts4 = pd.read_csv('./datasets_full/datasets_full.csv/traditional_spambots_4.csv/users.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Tweets\n",
    "\n",
    "# Genuine accounts.\n",
    "gen_tweets = pd.read_csv('./datasets_full/datasets_full.csv/genuine_accounts.csv/tweets.csv')\n",
    "\n",
    "# Social spambots.\n",
    "ss1_tweets = pd.read_csv('./datasets_full/datasets_full.csv/social_spambots_1.csv/tweets.csv')\n",
    "ss2_tweets = pd.read_csv('./datasets_full/datasets_full.csv/social_spambots_2.csv/tweets.csv')\n",
    "ss3_tweets = pd.read_csv('./datasets_full/datasets_full.csv/social_spambots_3.csv/tweets.csv')\n",
    "\n",
    "# Traditional spambots.\n",
    "# ts1_tweets = pd.read_csv('./datasets_full/datasets_full.csv/traditional_spambots_1.csv/tweets.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Digital DNA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dna_from_tweets(tweets_df):\n",
    "    '''For each user id in tweets_df return a digital DNA string based on posting behaviour.'''\n",
    "    \n",
    "    # Add columns for counts of tweets, replies and retweets.\n",
    "    tweets_df['num_retweets'] = np.where(tweets_df['retweeted_status_id'] == 0, 0, 1)\n",
    "    tweets_df['num_replies'] = np.where(tweets_df['in_reply_to_status_id'] == 0, 0, 1)\n",
    "    tweets_df['num_tweets'] = np.where((tweets_df['num_retweets'] == 0) & (tweets_df['num_replies'] == 0), 1, 0)\n",
    "\n",
    "    # DNA alphabet for tweet (A), retweet (C) and reply (T).\n",
    "    tweets = tweets_df['num_tweets'] == 1\n",
    "    retweets = tweets_df['num_retweets'] == 1\n",
    "    replies = tweets_df['num_replies'] == 1\n",
    "\n",
    "    tweets_df.loc[:, 'DNA'] = np.where(retweets, 'C', np.where(replies, 'T', 'A'))\n",
    "\n",
    "    # Sort tweets by timestamp.\n",
    "    tweets_df = tweets_df[['user_id', 'timestamp', 'DNA']]\n",
    "    tweets_df = tweets_df.sort_values(by=['timestamp'])\n",
    "\n",
    "    # Create digital DNA string for account.\n",
    "    dna = tweets_df.groupby(by=['user_id'])['DNA'].agg(lambda x: ''.join(x))\n",
    "    \n",
    "    return dna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress_dna_df(dna):\n",
    "    '''Return a dataframe with compression facts for a series of dna.'''\n",
    "\n",
    "    # Convert DNA in string object to bytes object.\n",
    "    dna_bytes = dna.apply(lambda s: s.encode('utf-8'))\n",
    "\n",
    "    # Run compression on each DNA string in the sample.\n",
    "    dna_compressed = dna_bytes.apply(lambda b: zlib.compress(b))\n",
    "\n",
    "    # Create dataframe with compression facts.\n",
    "    dna_df = pd.DataFrame({'dna': dna,\n",
    "                           'original_dna_size': dna_bytes.apply(sys.getsizeof), \n",
    "                           'compressed_dna_size': dna_compressed.apply(sys.getsizeof)})\n",
    "    \n",
    "    dna_df['compression_ratio'] = dna_df['original_dna_size'] / dna_df['compressed_dna_size']\n",
    "    \n",
    "    return dna_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_test, predictions):\n",
    "    '''Return a dataframe with accuracy, precision, recall and f1 scores for predictions.'''\n",
    "    \n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, predictions).ravel()\n",
    "    specificity = tn / (tn+fp)\n",
    "    \n",
    "    results = [\n",
    "        {\n",
    "            'Metric': 'Accuracy',\n",
    "            'Score': accuracy_score(y_test, predictions)\n",
    "        },\n",
    "        {\n",
    "            'Metric': 'Precision',\n",
    "            'Score': precision_score(y_test, predictions)\n",
    "        },\n",
    "        {\n",
    "            'Metric': 'Recall',\n",
    "            'Score': recall_score(y_test, predictions)\n",
    "        },\n",
    "        {\n",
    "            'Metric': 'F1 Score',\n",
    "            'Score': f1_score(y_test, predictions)\n",
    "        },\n",
    "        {\n",
    "            'Metric': 'MCC',\n",
    "            'Score': matthews_corrcoef(y_test, predictions)\n",
    "        },\n",
    "        {\n",
    "            'Metric': 'Specificity',\n",
    "            'Score': specificity\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_permutation(s):\n",
    "    s = list(s)\n",
    "    random.shuffle(s)\n",
    "    return ''.join(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_predict_evaluate(dna, features, test_size=0.5):\n",
    "    '''Train a Logistic Regression model with given features\n",
    "    using default parameters on a random sample of data.'''\n",
    "\n",
    "    # Randomly shuffle the dna dataframe.\n",
    "    dna = utils.shuffle(dna)\n",
    "\n",
    "    # Features and labels.\n",
    "    X = dna[features + ['dna']]\n",
    "    y = dna.loc[:, 'label']\n",
    "\n",
    "    # Split the dataset for training and testing using Logistic Regression.\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "\n",
    "    # Apply permutation to the DNA sequences in the test set and recompute compression statistics.\n",
    "    X_test = compress_dna_df(X_test['dna'].replace(np.nan, '', regex=True).apply(random_permutation))\n",
    "    \n",
    "    X_train = X_train[features]\n",
    "    X_test = X_test[features]\n",
    "    \n",
    "    # Logistic Regression classifier with default parameters.\n",
    "    classifier = LogisticRegression()\n",
    "\n",
    "    # Train the classifier.\n",
    "    start_train = time.time()\n",
    "    classifier.fit(X_train, y_train)\n",
    "    end_train = time.time()\n",
    "\n",
    "    # Make predictions on the test set.\n",
    "    start_test = time.time()\n",
    "    predictions = classifier.predict(X_test)\n",
    "    end_test = time.time()\n",
    "\n",
    "    # Evaluation on the test set.\n",
    "    results = evaluate(y_test, predictions)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Set #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genuine accounts in test set 1.\n",
    "gen_test1 = gen[gen['test_set_1'] == 1]\n",
    "\n",
    "# Social spambots in test set 1.\n",
    "ss1_test_1 = ss1[ss1['test_set_1'] == 1]\n",
    "\n",
    "\n",
    "# Tweets for genuine accounts in test set 1.\n",
    "gen_tweets_test1 = gen_tweets[gen_tweets['user_id'].isin(gen_test1['id'])]\n",
    "\n",
    "# Tweets for spambot accounts in test set 1.\n",
    "ss1_tweets_test1 = ss1_tweets[ss1_tweets['user_id'].isin(ss1_test_1['id'])]\n",
    "\n",
    "\n",
    "# DNA for genuine accounts in test set 1.\n",
    "gen_dna_test1 = create_dna_from_tweets(gen_tweets_test1)\n",
    "\n",
    "# DNA for spambots in test set 1.\n",
    "ss1_dna_test1 = create_dna_from_tweets(ss1_tweets_test1)\n",
    "\n",
    "# DNA string compression for genuine accounts in test set 1.\n",
    "gen_dna_test1 = compress_dna_df(gen_dna_test1)\n",
    "\n",
    "# DNA string compression for spambots in test set 1.\n",
    "ss1_dna_test1 = compress_dna_df(ss1_dna_test1)\n",
    "\n",
    "# Statistics for accounts with no tweets in the dataset\n",
    "gen_with_no_tweets_test1 = gen_test1[~gen_test1['id'].isin(gen_dna_test1.index)]\n",
    "\n",
    "gen_with_no_tweets_dna_test1 = pd.DataFrame({'id': gen_with_no_tweets_test1['id'], \n",
    "                                             'original_dna_size': 33, \n",
    "                                             'compressed_dna_size': 41, \n",
    "                                             'compression_ratio': 0.80, \n",
    "                                             'label': 0})\n",
    "\n",
    "gen_with_no_tweets_dna_test1 = gen_with_no_tweets_dna_test1.set_index('id')\n",
    "\n",
    "gen_dna_test1 = pd.concat([gen_dna_test1, gen_with_no_tweets_dna_test1])\n",
    "\n",
    "# Combine test set 1 accounts into a single dataframe.\n",
    "dna_test1 = pd.concat([gen_dna_test1, ss1_dna_test1])\n",
    "\n",
    "# Add a column for label to the dataframes.\n",
    "gen_dna_test1['label'] = 0\n",
    "ss1_dna_test1['label'] = 1\n",
    "\n",
    "\n",
    "# Combine test set 1 accounts into a single dataframe.\n",
    "dna_test1 = pd.concat([gen_dna_test1, ss1_dna_test1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std.</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.976988</td>\n",
       "      <td>0.003309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.976594</td>\n",
       "      <td>0.003440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCC</th>\n",
       "      <td>0.954188</td>\n",
       "      <td>0.006486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.986247</td>\n",
       "      <td>0.004649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.967194</td>\n",
       "      <td>0.008218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Specificity</th>\n",
       "      <td>0.986651</td>\n",
       "      <td>0.004605</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Mean      Std.\n",
       "Metric                         \n",
       "Accuracy     0.976988  0.003309\n",
       "F1 Score     0.976594  0.003440\n",
       "MCC          0.954188  0.006486\n",
       "Precision    0.986247  0.004649\n",
       "Recall       0.967194  0.008218\n",
       "Specificity  0.986651  0.004605"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame()\n",
    "\n",
    "for i in range(100):\n",
    "    np.random.seed(i)\n",
    "    results = pd.concat([results, train_predict_evaluate(dna_test1, ['original_dna_size', 'compressed_dna_size'])])\n",
    "\n",
    "results_with_length = results.groupby(by=['Metric']) \\\n",
    "               .mean() \\\n",
    "               .rename({'Score': 'Mean'}, axis=1) \\\n",
    "               .join(results.groupby(by=['Metric'])\n",
    "                            .std() \\\n",
    "                            .rename({'Score': 'Std.'}, axis=1))\n",
    "\n",
    "results_with_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std.</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.975853</td>\n",
       "      <td>0.003179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.975223</td>\n",
       "      <td>0.003342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCC</th>\n",
       "      <td>0.952331</td>\n",
       "      <td>0.006186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.993813</td>\n",
       "      <td>0.002653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.957342</td>\n",
       "      <td>0.006337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Specificity</th>\n",
       "      <td>0.994117</td>\n",
       "      <td>0.002513</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Mean      Std.\n",
       "Metric                         \n",
       "Accuracy     0.975853  0.003179\n",
       "F1 Score     0.975223  0.003342\n",
       "MCC          0.952331  0.006186\n",
       "Precision    0.993813  0.002653\n",
       "Recall       0.957342  0.006337\n",
       "Specificity  0.994117  0.002513"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame()\n",
    "\n",
    "for i in range(100):\n",
    "    np.random.seed(i)\n",
    "    results = pd.concat([results, train_predict_evaluate(dna_test1, ['original_dna_size', 'compression_ratio'])])\n",
    "\n",
    "results_with_ratio = results.groupby(by=['Metric']) \\\n",
    "               .mean() \\\n",
    "               .rename({'Score': 'Mean'}, axis=1) \\\n",
    "               .join(results.groupby(by=['Metric'])\n",
    "                            .std() \\\n",
    "                            .rename({'Score': 'Std.'}, axis=1))\n",
    "\n",
    "results_with_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "String Compression - Compressed DNA Size & 0.977 & 0.986 & 0.967 & 0.977 & 0.954 & 0.987 \\\\\n",
      "String Compression - Compression Ratio & 0.976 & 0.994 & 0.957 & 0.975 & 0.952 & 0.994 \\\\\n"
     ]
    }
   ],
   "source": [
    "print('String Compression - Compressed DNA Size &',\n",
    "      '{:.3f} &'.format(results_with_length['Mean']['Accuracy']),\n",
    "      '{:.3f} &'.format(results_with_length['Mean']['Precision']),\n",
    "      '{:.3f} &'.format(results_with_length['Mean']['Recall']),\n",
    "      '{:.3f} &'.format(results_with_length['Mean']['F1 Score']),\n",
    "      '{:.3f} &'.format(results_with_length['Mean']['MCC']),\n",
    "      '{:.3f} \\\\\\\\'.format(results_with_length['Mean']['Specificity']))\n",
    "\n",
    "print('String Compression - Compression Ratio &',\n",
    "      '{:.3f} &'.format(results_with_ratio['Mean']['Accuracy']),\n",
    "      '{:.3f} &'.format(results_with_ratio['Mean']['Precision']),\n",
    "      '{:.3f} &'.format(results_with_ratio['Mean']['Recall']),\n",
    "      '{:.3f} &'.format(results_with_ratio['Mean']['F1 Score']),\n",
    "      '{:.3f} &'.format(results_with_ratio['Mean']['MCC']),\n",
    "      '{:.3f} \\\\\\\\'.format(results_with_ratio['Mean']['Specificity']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Set #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genuine accounts in test set 2.\n",
    "gen_test2 = gen[gen['test_set_2'] == 1]\n",
    "\n",
    "# Social spambots in test set 2.\n",
    "ss3_test_2 = ss3[ss3['test_set_2'] == 1]\n",
    "\n",
    "\n",
    "# Tweets for genuine accounts in test set 2.\n",
    "gen_tweets_test2 = gen_tweets[gen_tweets['user_id'].isin(gen_test2['id'])]\n",
    "\n",
    "# Tweets for spambot accounts in test set 2.\n",
    "ss3_tweets_test2 = ss3_tweets[ss3_tweets['user_id'].isin(ss3_test_2['id'])]\n",
    "\n",
    "\n",
    "# DNA for genuine accounts in test set 2.\n",
    "gen_dna_test2 = create_dna_from_tweets(gen_tweets_test2)\n",
    "\n",
    "# DNA for spambots in test set 2.\n",
    "ss3_dna_test2 = create_dna_from_tweets(ss3_tweets_test2)\n",
    "\n",
    "# DNA string compression for genuine accounts in test set 2.\n",
    "gen_dna_test2 = compress_dna_df(gen_dna_test2)\n",
    "\n",
    "# DNA string compression for spambots in test set 2.\n",
    "ss3_dna_test2 = compress_dna_df(ss3_dna_test2)\n",
    "\n",
    "# Statistics for accounts with no tweets in the dataset\n",
    "gen_with_no_tweets_test2 = gen_test2[~gen_test2['id'].isin(gen_dna_test2.index)]\n",
    "\n",
    "gen_with_no_tweets_dna_test2 = pd.DataFrame({'id': gen_with_no_tweets_test2['id'], \n",
    "                                             'original_dna_size': 33, \n",
    "                                             'compressed_dna_size': 41, \n",
    "                                             'compression_ratio': 0.80, \n",
    "                                             'label': 0})\n",
    "\n",
    "gen_with_no_tweets_dna_test2 = gen_with_no_tweets_dna_test2.set_index('id')\n",
    "\n",
    "gen_dna_test2 = pd.concat([gen_dna_test2, gen_with_no_tweets_dna_test2])\n",
    "\n",
    "# Combine test set 2 accounts into a single dataframe.\n",
    "dna_test2 = pd.concat([gen_dna_test2, ss3_dna_test2])\n",
    "\n",
    "# Add a column for label to the dataframes.\n",
    "gen_dna_test2['label'] = 0\n",
    "ss3_dna_test2['label'] = 1\n",
    "\n",
    "\n",
    "# Combine test set 2 accounts into a single dataframe.\n",
    "dna_test2 = pd.concat([gen_dna_test2, ss3_dna_test2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std.</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.967673</td>\n",
       "      <td>0.004843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.966010</td>\n",
       "      <td>0.005282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCC</th>\n",
       "      <td>0.936210</td>\n",
       "      <td>0.009463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.988903</td>\n",
       "      <td>0.008266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.944299</td>\n",
       "      <td>0.011468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Specificity</th>\n",
       "      <td>0.989878</td>\n",
       "      <td>0.007627</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Mean      Std.\n",
       "Metric                         \n",
       "Accuracy     0.967673  0.004843\n",
       "F1 Score     0.966010  0.005282\n",
       "MCC          0.936210  0.009463\n",
       "Precision    0.988903  0.008266\n",
       "Recall       0.944299  0.011468\n",
       "Specificity  0.989878  0.007627"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame()\n",
    "\n",
    "for i in range(100):\n",
    "    np.random.seed(i)\n",
    "    results = pd.concat([results, train_predict_evaluate(dna_test2, ['original_dna_size', 'compressed_dna_size'])])\n",
    "\n",
    "results_with_length = results.groupby(by=['Metric']) \\\n",
    "               .mean() \\\n",
    "               .rename({'Score': 'Mean'}, axis=1) \\\n",
    "               .join(results.groupby(by=['Metric'])\n",
    "                            .std() \\\n",
    "                            .rename({'Score': 'Std.'}, axis=1))\n",
    "\n",
    "results_with_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std.</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.975136</td>\n",
       "      <td>0.006121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.973867</td>\n",
       "      <td>0.006669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCC</th>\n",
       "      <td>0.951034</td>\n",
       "      <td>0.011832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.995462</td>\n",
       "      <td>0.003355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.953288</td>\n",
       "      <td>0.012948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Specificity</th>\n",
       "      <td>0.995881</td>\n",
       "      <td>0.003028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Mean      Std.\n",
       "Metric                         \n",
       "Accuracy     0.975136  0.006121\n",
       "F1 Score     0.973867  0.006669\n",
       "MCC          0.951034  0.011832\n",
       "Precision    0.995462  0.003355\n",
       "Recall       0.953288  0.012948\n",
       "Specificity  0.995881  0.003028"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame()\n",
    "\n",
    "for i in range(100):\n",
    "    np.random.seed(i)\n",
    "    results = pd.concat([results, train_predict_evaluate(dna_test2, ['original_dna_size', 'compression_ratio'])])\n",
    "\n",
    "results_with_ratio = results.groupby(by=['Metric']) \\\n",
    "               .mean() \\\n",
    "               .rename({'Score': 'Mean'}, axis=1) \\\n",
    "               .join(results.groupby(by=['Metric'])\n",
    "                            .std() \\\n",
    "                            .rename({'Score': 'Std.'}, axis=1))\n",
    "\n",
    "results_with_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "String Compression - Compressed DNA Size & 0.968 & 0.989 & 0.944 & 0.966 & 0.936 & 0.990 \\\\\n",
      "String Compression - Compression Ratio & 0.975 & 0.995 & 0.953 & 0.974 & 0.951 & 0.996 \\\\\n"
     ]
    }
   ],
   "source": [
    "print('String Compression - Compressed DNA Size &',\n",
    "      '{:.3f} &'.format(results_with_length['Mean']['Accuracy']),\n",
    "      '{:.3f} &'.format(results_with_length['Mean']['Precision']),\n",
    "      '{:.3f} &'.format(results_with_length['Mean']['Recall']),\n",
    "      '{:.3f} &'.format(results_with_length['Mean']['F1 Score']),\n",
    "      '{:.3f} &'.format(results_with_length['Mean']['MCC']),\n",
    "      '{:.3f} \\\\\\\\'.format(results_with_length['Mean']['Specificity']))\n",
    "\n",
    "print('String Compression - Compression Ratio &',\n",
    "      '{:.3f} &'.format(results_with_ratio['Mean']['Accuracy']),\n",
    "      '{:.3f} &'.format(results_with_ratio['Mean']['Precision']),\n",
    "      '{:.3f} &'.format(results_with_ratio['Mean']['Recall']),\n",
    "      '{:.3f} &'.format(results_with_ratio['Mean']['F1 Score']),\n",
    "      '{:.3f} &'.format(results_with_ratio['Mean']['MCC']),\n",
    "      '{:.3f} \\\\\\\\'.format(results_with_ratio['Mean']['Specificity']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
